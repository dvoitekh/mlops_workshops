{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scann tensorflow optuna --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScaNN Demo with GloVe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import time\n",
    "import optuna\n",
    "import scann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    response = requests.get(\"http://ann-benchmarks.com/glove-100-angular.hdf5\")\n",
    "    loc = os.path.join(tmp, \"glove.hdf5\")\n",
    "    with open(loc, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    glove_h5py = h5py.File(loc, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['distances', 'neighbors', 'test', 'train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(glove_h5py.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183514, 100)\n",
      "(10000, 100)\n"
     ]
    }
   ],
   "source": [
    "dataset = glove_h5py['train']\n",
    "queries = glove_h5py['test']\n",
    "print(dataset.shape)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ScaNN searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 12:36:06.137659: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 249797\n",
      "2022-07-01 12:36:14.720796: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 8.583060288s.\n"
     ]
    }
   ],
   "source": [
    "normalized_dataset = dataset / np.linalg.norm(dataset, axis=1)[:, np.newaxis]\n",
    "# configure ScaNN as a tree - asymmetric hash hybrid with reordering\n",
    "# anisotropic quantization as described in the paper; see README\n",
    "\n",
    "# use scann.scann_ops.build() to instead create a TensorFlow-compatible searcher\n",
    "searcher = scann.scann_ops_pybind.builder(normalized_dataset, 10, \"dot_product\").tree(\n",
    "    num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
    "    2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index\n",
    "!mkdir scann\n",
    "searcher.serialize('scann/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 38:5: text format contains deprecated field \"min_cluster_size\"\n"
     ]
    }
   ],
   "source": [
    "# load index\n",
    "searcher = scann.scann_ops_pybind.load_searcher('scann/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(neighbors, true_neighbors):\n",
    "    total = 0\n",
    "    for gt_row, row in zip(true_neighbors, neighbors):\n",
    "        total += np.intersect1d(gt_row, row).shape[0]\n",
    "    return total / true_neighbors.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScaNN interface features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.90015\n",
      "Time: 4.384388208389282\n"
     ]
    }
   ],
   "source": [
    "# this will search the top 100 of the 2000 leaves, and compute\n",
    "# the exact dot products of the top 100 candidates from asymmetric\n",
    "# hashing to get the final top 10 candidates.\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries)\n",
    "end = time.time()\n",
    "\n",
    "# we are given top 100 neighbors in the ground truth, so select top 10\n",
    "print(\"Recall:\", compute_recall(neighbors, glove_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.92392\n",
      "Time: 3.3855273723602295\n"
     ]
    }
   ],
   "source": [
    "# increasing the leaves to search increases recall at the cost of speed\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries, leaves_to_search=150)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Recall:\", compute_recall(neighbors, glove_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.93145\n",
      "Time: 4.06306791305542\n"
     ]
    }
   ],
   "source": [
    "# increasing reordering (the exact scoring of top AH candidates) has a similar effect.\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries, leaves_to_search=150, pre_reorder_num_neighbors=250)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Recall:\", compute_recall(neighbors, glove_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10000, 10)\n",
      "(10000, 20) (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "# we can also dynamically configure the number of neighbors returned\n",
    "# currently returns 10 as configued in ScannBuilder()\n",
    "neighbors, distances = searcher.search_batched(queries)\n",
    "print(neighbors.shape, distances.shape)\n",
    "\n",
    "# now returns 20\n",
    "neighbors, distances = searcher.search_batched(queries, final_num_neighbors=20)\n",
    "print(neighbors.shape, distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 97478 846101 671078 727732 544474]\n",
      "[2.5518737 2.539792  2.5383418 2.5097368 2.4656374]\n",
      "Latency (ms): 2.3496150970458984\n"
     ]
    }
   ],
   "source": [
    "# we have been exclusively calling batch search so far; the single-query call has the same API\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search(queries[0], final_num_neighbors=5)\n",
    "end = time.time()\n",
    "\n",
    "print(neighbors)\n",
    "print(distances)\n",
    "print(\"Latency (ms):\", 1000*(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-01 20:24:35,470]\u001b[0m A new study created in memory with name: no-name-e7521fb7-262d-4a79-ac39-7543f53215d6\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:24:36.507987: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:25:07.638937: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 31.130865035s.\n",
      "\u001b[32m[I 2022-07-01 20:25:37,742]\u001b[0m Trial 0 finished with value: 0.91082 and parameters: {'num_leaves': 800, 'num_leaves_to_search': 100, 'reorder': 50}. Best is trial 0 with value: 0.91082.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:25:38.676256: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:26:30.714564: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 52.038214956s.\n",
      "\u001b[32m[I 2022-07-01 20:27:07,375]\u001b[0m Trial 1 finished with value: 0.96882 and parameters: {'num_leaves': 1400, 'num_leaves_to_search': 300, 'reorder': 100}. Best is trial 1 with value: 0.96882.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:27:08.344783: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:27:45.643996: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 37.299131542s.\n",
      "\u001b[32m[I 2022-07-01 20:28:17,588]\u001b[0m Trial 2 finished with value: 0.93698 and parameters: {'num_leaves': 1000, 'num_leaves_to_search': 100, 'reorder': 100}. Best is trial 1 with value: 0.96882.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:28:18.539273: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:28:55.553407: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 37.014045139s.\n",
      "\u001b[32m[I 2022-07-01 20:29:34,987]\u001b[0m Trial 3 finished with value: 0.97367 and parameters: {'num_leaves': 1000, 'num_leaves_to_search': 300, 'reorder': 100}. Best is trial 3 with value: 0.97367.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:29:35.875105: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:30:06.698964: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 30.823775277s.\n",
      "\u001b[32m[I 2022-07-01 20:30:53,856]\u001b[0m Trial 4 finished with value: 0.9897 and parameters: {'num_leaves': 800, 'num_leaves_to_search': 500, 'reorder': 150}. Best is trial 4 with value: 0.9897.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:30:54.765180: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:31:25.334321: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 30.569063216s.\n",
      "\u001b[32m[I 2022-07-01 20:31:54,949]\u001b[0m Trial 5 finished with value: 0.91082 and parameters: {'num_leaves': 800, 'num_leaves_to_search': 100, 'reorder': 50}. Best is trial 4 with value: 0.9897.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:31:55.852563: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:32:47.388786: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 51.536139552s.\n",
      "\u001b[32m[I 2022-07-01 20:33:24,757]\u001b[0m Trial 6 finished with value: 0.96882 and parameters: {'num_leaves': 1400, 'num_leaves_to_search': 300, 'reorder': 100}. Best is trial 4 with value: 0.9897.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:33:25.717334: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:34:17.021561: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 51.30414675s.\n",
      "\u001b[32m[I 2022-07-01 20:35:00,588]\u001b[0m Trial 7 finished with value: 0.94211 and parameters: {'num_leaves': 1400, 'num_leaves_to_search': 500, 'reorder': 50}. Best is trial 4 with value: 0.9897.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:35:01.361404: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:35:50.523078: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 49.161589657s.\n",
      "\u001b[32m[I 2022-07-01 20:36:20,063]\u001b[0m Trial 8 finished with value: 0.89867 and parameters: {'num_leaves': 1400, 'num_leaves_to_search': 100, 'reorder': 50}. Best is trial 4 with value: 0.9897.\u001b[0m\n",
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:36:21.184609: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:37:03.760102: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 42.575407896s.\n",
      "\u001b[32m[I 2022-07-01 20:37:41,769]\u001b[0m Trial 9 finished with value: 0.97931 and parameters: {'num_leaves': 1200, 'num_leaves_to_search': 300, 'reorder': 150}. Best is trial 4 with value: 0.9897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  10\n",
      "Best trial:\n",
      "Value: 0.9897\n",
      "Params:\n",
      "    num_leaves: 800\n",
      "    num_leaves_to_search: 500\n",
      "    reorder: 150\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 800, 1400, step=200)\n",
    "    num_leaves_to_search = trial.suggest_int(\"num_leaves_to_search\", 100, 500, step=200)\n",
    "    reorder = trial.suggest_int(\"reorder\", 50, 150, step=50)\n",
    "    \n",
    "    searcher = scann.scann_ops_pybind.builder(normalized_dataset, 10, \"dot_product\").tree(\n",
    "        num_leaves=num_leaves, num_leaves_to_search=num_leaves_to_search, training_sample_size=len(normalized_dataset)).score_ah(\n",
    "        2, anisotropic_quantization_threshold=0.2).reorder(reorder).build()\n",
    "    \n",
    "    neighbors, distances = searcher.search_batched(queries)\n",
    "    \n",
    "    return compute_recall(neighbors, glove_h5py['neighbors'][:, :10])\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"Value: {trial.value}\")\n",
    "print(\"Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf WARNING external/com_google_protobuf/src/google/protobuf/text_format.cc:339] Warning parsing text-format research_scann.ScannConfig: 43:11: text format contains deprecated field \"min_cluster_size\"\n",
      "2022-07-01 20:39:27.198433: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 1183514\n",
      "2022-07-01 20:39:57.768290: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:88] PartitionerFactory ran in 30.569770166s.\n"
     ]
    }
   ],
   "source": [
    "searcher = scann.scann_ops_pybind.builder(normalized_dataset, 10, \"dot_product\").tree(\n",
    "    num_leaves=800, num_leaves_to_search=500, training_sample_size=len(normalized_dataset)).score_ah(\n",
    "    2, anisotropic_quantization_threshold=0.2).reorder(150).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9897\n",
      "Time: 24.332216024398804\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries)\n",
    "end = time.time()\n",
    "\n",
    "# we are given top 100 neighbors in the ground truth, so select top 10\n",
    "print(\"Recall:\", compute_recall(neighbors, glove_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.004163503646850586\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "neighbors, distances = searcher.search(queries[0])\n",
    "end = time.time()\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
